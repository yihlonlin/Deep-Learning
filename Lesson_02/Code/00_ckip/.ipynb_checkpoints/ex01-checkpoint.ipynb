{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ckip-segmenter\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/b6/f32a83f415581ae6b901bdcef0d9560e6b20f8f4fceb64bec7e1700f370c/ckip_segmenter-1.0.2-py3-none-any.whl\n",
      "Installing collected packages: ckip-segmenter\n",
      "Successfully installed ckip-segmenter-1.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install ckip-segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckip import CkipSegmenter\n",
    "segmenter = CkipSegmenter()\n",
    "\n",
    "text = '詞是最小有意義且可以自由使用的語言單位。任何語言處理的系統都必須先能分辨文本中的詞才能進行進一步的處理'\n",
    "corpus = [\n",
    "    '詞是最小有意義且可以自由使用的語言單位',\n",
    "    '任何語言處理的系統都必須先能分辨文本中的詞才能進行進一步的處理',\n",
    "    '例如機器翻譯、語言分析、語言了解、資訊抽取',\n",
    "    '因此中文自動分詞的工作成了語言處理不可或缺的技術',\n",
    "    '基本上自動分詞多利用詞典中收錄的詞和文本做比對',\n",
    "    '找出可能包含的詞，由於存在歧義的切分結果',\n",
    "    '因此多數的中文分詞程式多討論如何解決分詞歧義的問題',\n",
    "    '而較少討論如何處理詞典中未收錄的詞出現的問題（新詞如何辨認）',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.res: [('詞', 'Na'), ('是', 'SHI'), ('最', 'Dfa'), ('小', 'VH'), ('有', 'V_2'), ('意義', 'Na'), ('且', 'Cbb'), ('可以', 'D'), ('自由', 'VH'), ('使用', 'VC'), ('的', 'DE'), ('語言', 'Na'), ('單位', 'Na'), ('。', 'PERIODCATEGORY'), ('任何', 'Neqa'), ('語言', 'Na'), ('處理', 'VC'), ('的', 'DE'), ('系統', 'Na'), ('都', 'D'), ('必須', 'D'), ('先能', 'Nb'), ('分辨', 'VE'), ('文本', 'Nb'), ('中', 'Ng'), ('的', 'DE'), ('詞', 'Na'), ('才能', 'Na'), ('進行', 'VC'), ('進一步', 'D'), ('的', 'DE'), ('處理', 'VC')]\n",
      "\n",
      "result.tok: ['詞', '是', '最', '小', '有', '意義', '且', '可以', '自由', '使用', '的', '語言', '單位', '。', '任何', '語言', '處理', '的', '系統', '都', '必須', '先能', '分辨', '文本', '中', '的', '詞', '才能', '進行', '進一步', '的', '處理']\n",
      "\n",
      "result.pos: ['Na', 'SHI', 'Dfa', 'VH', 'V_2', 'Na', 'Cbb', 'D', 'VH', 'VC', 'DE', 'Na', 'Na', 'PERIODCATEGORY', 'Neqa', 'Na', 'VC', 'DE', 'Na', 'D', 'D', 'Nb', 'VE', 'Nb', 'Ng', 'DE', 'Na', 'Na', 'VC', 'D', 'DE', 'VC']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = segmenter.seg(text)\n",
    "# result.res is a list of tuples contain a token and its pos-tag.\n",
    "print('result.res: {}\\n'.format(result.res))\n",
    "\n",
    "# result.tok and result.pos contains only tokens and pos-tags respectively.\n",
    "print('result.tok: {}\\n'.format(result.tok))\n",
    "print('result.pos: {}\\n'.format(result.pos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
